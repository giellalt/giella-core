## Process this file with automake to produce Makefile.in

## Copyright (C) 2011 Samediggi

## This program is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.

## This program is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.

## You should have received a copy of the GNU General Public License
## along with this program.  If not, see <http://www.gnu.org/licenses/>.

####### Compilation variables: #######
HFST_REGEXP2FST_FLAGS="--xerox-composition=ON"

# Variable to hold filename for file containing all tags used
# (all symbols starting or ending with '+')
TAG_FILE=tags.txt
FLAG_FILE=flags.txt

# Variable to hold filename for fst used as source for extracting tags,
# sans extension
TAG_EXTRACTION_FST=$(top_builddir)/src/fst/analyser-%-gt-desc
TAG_EXTRACTION_TTS_FST=$(top_builddir)/src/fst/analyser-%-gt-output

####### Source file and target defs: ########
GT_DISAMB_TOKENISERS_FILTER_SRCS=
GT_GRAMCHECK_TOKENISERS_FILTER_SRCS=
GT_TTS_TOKENISERS_FILTER_SRCS=
GT_TOKENISER_URLFILTER_SRC=
GT_TOKENISER_EMOFILTER_SRC=

if WANT_TOKENISERS
GT_DISAMB_TOKENISERS_FILTER_SRCS+=make-disamb-CG-tags.regex \
						   disamb-tokeniser-flags.regex
GT_TOKENISER_URLFILTER_SRC+=make-url-CG-tags.regex
GT_TOKENISER_EMOFILTER_SRC+=make-emojis-CG-tags.regex

endif # WANT_TOKENISERS

if WANT_GRAMCHECK
GT_GRAMCHECK_TOKENISERS_FILTER_SRCS+=make-gramcheck-CG-tags.regex \
						   gramcheck-tokeniser-flags.regex
GT_TOKENISER_URLFILTER_SRC+=make-url-CG-tags.regex
GT_TOKENISER_EMOFILTER_SRC+=make-emojis-CG-tags.regex
endif # WANT_GRAMCHECK

if WANT_TTS
GT_TTS_TOKENISERS_FILTER_SRCS+=make-tts-CG-tags.regex \
						   tts-tokeniser-flags.regex
GT_TOKENISER_URLFILTER_SRC+=make-url-CG-tags.regex
GT_TOKENISER_EMOFILTER_SRC+=make-emojis-CG-tags.regex
endif # WANT_TTS

if HAVE_ALT_ORTHS
BASENAME_TOKEN_FILTERS_ORTH=
BASENAME_TOKEN_FILTERS_ORTH+=$(sort $(basename $(GT_DISAMB_TOKENISERS_FILTER_SRCS)))

# Only build grammar checker filters for alt orths if we really need them:
if WANT_ALT_ORTH_PROOFTOOLS
BASENAME_TOKEN_FILTERS_ORTH+=$(sort $(basename $(GT_GRAMCHECK_TOKENISERS_FILTER_SRCS)))
endif # WANT_ALT_ORTH_PROOFTOOLS

ALT_ORTH_TOKENISER_FILTER_SRCS=$(shell for ll in $(BASENAME_TOKEN_FILTERS_ORTH); do\
    for ld in $(ALT_ORTHS); do\
        echo "$$ll.$$ld.regex" ;\
    done ;\
done)
endif # HAVE_ALT_ORTHS


test:
	@echo
	@echo Alt-orth filter: $(GT_TOKENISERS_FILTER_ALL_SRCS)
	@echo



# The second variable is sorted to get rid of duplicates:
GT_TOKENISERS_FILTER_ALL_SRCS=\
        $(GT_DISAMB_TOKENISERS_FILTER_SRCS)    \
        $(GT_GRAMCHECK_TOKENISERS_FILTER_SRCS) \
        $(GT_TTS_TOKENISERS_FILTER_SRCS)       \
        $(sort $(GT_TOKENISER_URLFILTER_SRC) ) \
        $(GT_TOKENISER_EMOFILTER_SRC) \
        $(GT_LOCAL_TOKENISERS_FILTER_SRCS)     \
        $(ALT_ORTH_TOKENISER_FILTER_SRCS)      \
        $(GT_LOCAL_COPY_FILTER_SRCS)           \
        $(GENERATED_REGEXES)

# This is what we build:
noinst_DATA=$(GT_TOKENISERS_FILTER_TARGETS)

# Automatically detect the targets to be built:
GT_TOKENISERS_FILTER_TARGETS=

if WANT_TOKENISERS
if CAN_HFST
GT_TOKENISERS_FILTER_TARGETS+=\
        $(patsubst %.regex,%.hfst,$(GT_TOKENISERS_FILTER_ALL_SRCS))
endif # CAN_HFST

# If tokenisers are turned off:
else !WANT_TOKENISERS

# We still want to build filters for the grammar checker if they are enabled:
if WANT_GRAMCHECK
if CAN_HFST
GT_TOKENISERS_FILTER_TARGETS+=\
        $(patsubst %.regex,%.hfst,$(GT_TOKENISERS_FILTER_ALL_SRCS))
endif # CAN_HFST
endif # WANT_GRAMCHECK

# And we also want to build filters for the TTS tokeniser if it is enabled:
if WANT_TTS
if CAN_HFST
GT_TOKENISERS_FILTER_TARGETS+=\
        $(patsubst %.regex,%.hfst,$(GT_TOKENISERS_FILTER_ALL_SRCS))
endif # CAN_HFST
endif # WANT_TTS

endif # WANT_TOKENISERS

####### Build rules for creating regexes from tag list: #######

### Reformat tags:
make-%-CG-tags.regex: .generated/%-$(TAG_FILE)
	$(AM_V_GEN)$(GTCORE)/scripts/taglist2make_CG_tags_regex.sh $< > $@

%-tokeniser-flags.regex: .generated/%-$(FLAG_FILE)
	$(AM_V_GEN)$(GTCORE)/scripts/flaglist2make_flag_regex.sh $< > $@


# Alt-orth variant of the above
define alt_orth_token_filters
make-%-CG-tags.$(1).regex: .generated/%-$(1)-$(TAG_FILE)
	$$(AM_V_GEN)$(GTCORE)/scripts/taglist2make_CG_tags_regex.sh $$< > $$@

%-tokeniser-flags.$(1).regex: .generated/%-$(1)-$(FLAG_FILE)
	$$(AM_V_GEN)$(GTCORE)/scripts/flaglist2make_flag_regex.sh $$< > $$@

endef
$(foreach alt_orth,$(ALT_ORTHS),$(eval $(call alt_orth_token_filters,$(alt_orth))))



####### Copy regex files from the Giella core if not found locally: ########
%.regex: $(GIELLA_CORE)/fst-filters/%.regex
	$(AM_V_CP)cp -f $< $@

####### ... OR from $top_builddir/src/filters/ (generated regex's)
%.regex: $(top_builddir)/src/fst/filters/%.regex
	$(AM_V_CP)cp -f $< $@

####### ... OR from $top_srcdir/src/filters/ (language-specific regex's)
%.regex: $(top_srcdir)/src/fst/filters/%.regex
	$(AM_V_CP)cp -f $< $@

##########################################
# General build rules included from here:#

include $(top_srcdir)/../giella-core/am-shared/regex-include.am
include $(top_srcdir)/../giella-core/am-shared/hfst-format-include.am
include $(top_srcdir)/../giella-core/am-shared/tag-extraction-include.am
include $(top_srcdir)/../giella-core/am-shared/silent_build-include.am
include $(top_srcdir)/../giella-core/am-shared/dot-generated-dir.am

# vim: set ft=automake:
